"""Reflection Service.

Service for managing and utilizing reflections in AgentCore Memory.
Reflections are insights extracted from multiple episodes that identify
patterns, best practices, and lessons learned.

Reference: https://docs.aws.amazon.com/bedrock-agentcore/latest/devguide/episodic-memory-strategy.html
"""

from dataclasses import dataclass, field
from typing import Any

import structlog

from src.infrastructure.agentcore.memory_client import (
    AgentCoreMemoryClient,
    MemoryRecord,
)
from src.infrastructure.agentcore.memory_config import MemoryConfig

logger = structlog.get_logger()


@dataclass
class Reflection:
    """Represents a reflection (insight) from AgentCore Memory.
    
    Reflections are generated by analyzing multiple episodes to extract:
    - Success patterns: What approaches work well
    - Failure patterns: Common failure modes to avoid
    - Best practices: Optimal procedures for specific scenarios
    
    Attributes:
        id: Unique reflection identifier
        use_case: The type of scenario this reflection applies to
        insight: The main insight or learning
        success_patterns: List of patterns that lead to success
        failure_patterns: List of patterns that lead to failure
        best_practices: Recommended approaches
        episode_count: Number of episodes this reflection is based on
        timestamp: When the reflection was generated
        raw_data: Original data from AgentCore Memory
    """
    
    id: str
    use_case: str
    insight: str
    success_patterns: list[str] = field(default_factory=list)
    failure_patterns: list[str] = field(default_factory=list)
    best_practices: list[str] = field(default_factory=list)
    episode_count: int = 0
    timestamp: str = ""
    raw_data: dict[str, Any] = field(default_factory=dict)


class ReflectionService:
    """Service for managing reflections (insights) from episodic memory.
    
    Provides high-level operations for:
    - Retrieving relevant reflections for a use case
    - Building prompts that incorporate learned insights
    - Applying patterns to agent decision-making
    
    Example usage:
        ```python
        service = ReflectionService(memory_client, config)
        
        # Retrieve relevant reflections
        reflections = await service.retrieve_relevant_reflections(
            user_id="user-456",
            use_case="customer support inquiry"
        )
        
        # Build prompt with reflections
        prompt = service.build_reflection_prompt(reflections)
        ```
    """

    def __init__(
        self,
        memory_client: AgentCoreMemoryClient,
        config: MemoryConfig | None = None,
    ):
        """Initialize the reflection service.
        
        Args:
            memory_client: The low-level memory client
            config: Memory configuration (uses defaults if not provided)
        """
        self._client = memory_client
        self._config = config or MemoryConfig()

    def _build_namespace(self, user_id: str, tenant_id: str | None = None) -> str:
        """Build the namespace for reflection storage.
        
        Args:
            user_id: The user identifier
            tenant_id: Optional tenant identifier for multi-tenant isolation
        
        Returns:
            The namespace string (e.g., "/tenant/t123/reflections/u456")
        """
        prefix = self._config.reflection_namespace_prefix
        
        if tenant_id and self._config.enable_tenant_isolation:
            return f"{self._config.tenant_namespace_prefix}/{tenant_id}{prefix}/{user_id}"
        
        return f"{prefix}/{user_id}"

    async def retrieve_relevant_reflections(
        self,
        user_id: str,
        use_case: str,
        max_results: int | None = None,
        tenant_id: str | None = None,
        min_score: float = 0.4,
    ) -> list[Reflection]:
        """Retrieve reflections relevant to the given use case.
        
        Reflections are indexed by use case, allowing semantic search
        for insights that apply to the current scenario.
        
        Args:
            user_id: The user identifier
            use_case: Description of the current use case/scenario
            max_results: Maximum reflections to return (default from config)
            tenant_id: Optional tenant ID for multi-tenant scenarios
            min_score: Minimum relevance score (0-1)
        
        Returns:
            List of relevant Reflection objects, sorted by relevance
        """
        max_results = max_results or self._config.max_reflections_per_query
        namespace = self._build_namespace(user_id, tenant_id)
        
        records = await self._client.retrieve_memories(
            namespace=namespace,
            query=use_case,
            max_results=max_results,
            min_score=min_score,
        )
        
        reflections = [self._parse_reflection(record) for record in records]
        
        logger.info(
            "relevant_reflections_retrieved",
            user_id=user_id,
            use_case_preview=use_case[:50],
            reflection_count=len(reflections),
        )
        
        return reflections

    def _parse_reflection(self, record: MemoryRecord) -> Reflection:
        """Parse a MemoryRecord into a Reflection object.
        
        Args:
            record: The raw memory record from AgentCore
        
        Returns:
            Parsed Reflection object
        """
        content = record.content
        
        return Reflection(
            id=record.id,
            use_case=content.get("use_case", ""),
            insight=content.get("insight", content.get("summary", "")),
            success_patterns=content.get("success_patterns", []),
            failure_patterns=content.get("failure_patterns", []),
            best_practices=content.get("best_practices", []),
            episode_count=content.get("episode_count", 0),
            timestamp=record.timestamp,
            raw_data=content,
        )

    def build_reflection_prompt(
        self,
        reflections: list[Reflection],
        max_chars: int | None = None,
    ) -> str:
        """Build a prompt section from reflections.
        
        Creates a formatted string that can be included in the agent's
        system prompt to apply learned insights.
        
        Args:
            reflections: List of reflections to include
            max_chars: Maximum characters in output (default from config)
        
        Returns:
            Formatted prompt string
        """
        if not reflections:
            return ""
        
        max_chars = max_chars or self._config.reflection_context_max_chars
        lines: list[str] = ["## Insights from Past Experience:"]
        
        for ref in reflections:
            section = [f"\n### {ref.use_case}"]
            section.append(f"Insight: {ref.insight}")
            
            if ref.success_patterns:
                section.append("What works well:")
                for pattern in ref.success_patterns[:3]:  # Limit patterns
                    section.append(f"  - {pattern}")
            
            if ref.failure_patterns:
                section.append("What to avoid:")
                for pattern in ref.failure_patterns[:2]:  # Limit patterns
                    section.append(f"  - {pattern}")
            
            if ref.best_practices:
                section.append("Best practices:")
                for practice in ref.best_practices[:3]:  # Limit practices
                    section.append(f"  - {practice}")
            
            lines.extend(section)
        
        prompt = "\n".join(lines)
        
        # Truncate if too long
        if len(prompt) > max_chars:
            prompt = prompt[:max_chars - 3] + "..."
        
        return prompt

    def apply_patterns_to_decision(
        self,
        reflections: list[Reflection],
        proposed_action: str,
    ) -> dict[str, Any]:
        """Analyze a proposed action against learned patterns.
        
        Checks if the proposed action aligns with success patterns
        or risks matching failure patterns.
        
        Args:
            reflections: Relevant reflections to check against
            proposed_action: Description of the proposed action
        
        Returns:
            Analysis dict with:
            - risk_level: "low", "medium", or "high"
            - matching_success_patterns: Patterns that support this action
            - matching_failure_patterns: Patterns that warn against this action
            - recommendations: Suggested modifications
        """
        action_lower = proposed_action.lower()
        
        matching_success: list[str] = []
        matching_failure: list[str] = []
        recommendations: list[str] = []
        
        for ref in reflections:
            # Check success patterns
            for pattern in ref.success_patterns:
                if any(word in action_lower for word in pattern.lower().split()[:3]):
                    matching_success.append(pattern)
            
            # Check failure patterns
            for pattern in ref.failure_patterns:
                if any(word in action_lower for word in pattern.lower().split()[:3]):
                    matching_failure.append(pattern)
            
            # Add relevant best practices as recommendations
            for practice in ref.best_practices:
                if any(word in practice.lower() for word in action_lower.split()[:5]):
                    recommendations.append(practice)
        
        # Determine risk level
        if len(matching_failure) > len(matching_success):
            risk_level = "high"
        elif matching_failure:
            risk_level = "medium"
        else:
            risk_level = "low"
        
        return {
            "risk_level": risk_level,
            "matching_success_patterns": matching_success,
            "matching_failure_patterns": matching_failure,
            "recommendations": recommendations[:3],  # Limit recommendations
        }

    async def get_reflection_summary(
        self,
        user_id: str,
        tenant_id: str | None = None,
    ) -> dict[str, Any]:
        """Get a summary of all reflections for a user.
        
        Args:
            user_id: The user identifier
            tenant_id: Optional tenant ID
        
        Returns:
            Summary dictionary with reflection statistics
        """
        namespace = self._build_namespace(user_id, tenant_id)
        
        # Retrieve reflections with broad query
        records = await self._client.retrieve_memories(
            namespace=namespace,
            query="*",
            max_results=50,
        )
        
        reflections = [self._parse_reflection(r) for r in records]
        
        total_success_patterns = sum(len(r.success_patterns) for r in reflections)
        total_failure_patterns = sum(len(r.failure_patterns) for r in reflections)
        total_best_practices = sum(len(r.best_practices) for r in reflections)
        total_episodes_analyzed = sum(r.episode_count for r in reflections)
        
        use_cases = [r.use_case for r in reflections if r.use_case]
        
        return {
            "total_reflections": len(reflections),
            "total_episodes_analyzed": total_episodes_analyzed,
            "total_success_patterns": total_success_patterns,
            "total_failure_patterns": total_failure_patterns,
            "total_best_practices": total_best_practices,
            "use_cases": list(set(use_cases))[:10],  # Unique use cases
        }
